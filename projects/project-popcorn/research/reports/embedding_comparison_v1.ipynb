{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 임베딩 모델 비교 테스트 결과\n",
    "\n",
    "**Cross-Domain 법안 감지를 위한 임베딩 모델 성능 평가**\n",
    "\n",
    "- Project: Popcorn\n",
    "- Date: 2026-01-15\n",
    "- Version: v1 (법안명만 사용)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 개요\n",
    "\n",
    "### 1.1 테스트 목적\n",
    "\n",
    "타 상임위 소관 법안 중 **산업통상자원부 R&R과 연관된 법안**을 선제 감지하기 위한 최적의 임베딩 모델을 선정합니다.\n",
    "\n",
    "### 1.2 테스트 대상 모델\n",
    "\n",
    "| 모델 | 제공사 | 특징 |\n",
    "|------|--------|------|\n",
    "| Solar Embedding | Upstage | 한국어 특화, API 기반 |\n",
    "| text-embedding-3-small | OpenAI | 다국어 지원, 저비용 |\n",
    "| Multilingual-E5-Large | Intfloat | 오픈소스, 로컬 실행 |\n",
    "\n",
    "### 1.3 평가 데이터\n",
    "\n",
    "- **R&R 데이터**: 산업통상자원부 R&R (증강 버전, 822자)\n",
    "- **테스트 법안**: 22대 국회 법안 100건 (10개 상임위 × 10건)\n",
    "- **Golden Set**: Cross-Domain 감지 테스트용 5건"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Golden Set 구성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import json\nimport pandas as pd\nfrom pathlib import Path\n\n# 데이터 로드 (research/reports/ 기준)\ndata_dir = Path(\"../../data\")\ngolden_data = json.load(open(data_dir / \"golden_set.json\", encoding=\"utf-8\"))\n\ngolden_df = pd.DataFrame(golden_data[\"bills\"])\ngolden_df = golden_df[[\"golden_id\", \"difficulty\", \"bill_name\", \"committee\", \"propose_dt\"]]\ngolden_df.columns = [\"ID\", \"난이도\", \"법안명\", \"소관위\", \"발의일\"]\ngolden_df"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Golden Set 선정 기준\n",
    "\n",
    "| 난이도 | 선정 기준 | 예시 |\n",
    "|--------|----------|------|\n",
    "| **Easy** | 산업부 키워드 직접 포함 | 탄소중립, 중대재해 |\n",
    "| **Medium** | 간접 연관 (데이터, AI) | 개인정보보호법 |\n",
    "| **Hard** | Cross-Domain 핵심 타겟 | 약사법(공장 설비), 국유재산특례제한법(세제) |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 테스트 결과"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# 결과 로드\nresults_path = Path(\"../results/embedding_comparison.json\")\nresults = json.load(open(results_path, encoding=\"utf-8\"))\n\n# 종합 비교표 생성\nsummary_data = []\nfor model_key in [\"solar\", \"openai\", \"multilingual_e5\"]:\n    if model_key in results and \"evaluation\" in results[model_key]:\n        eval_data = results[model_key][\"evaluation\"]\n        summary_data.append({\n            \"모델\": results[model_key][\"model\"],\n            \"Recall@10\": f\"{eval_data['recall_at_10']:.1%}\",\n            \"Recall@20\": f\"{eval_data['recall_at_20']:.1%}\",\n            \"Recall@50\": f\"{eval_data['recall_at_50']:.1%}\",\n            \"Hard 평균순위\": f\"{eval_data['avg_hard_rank']:.1f}\",\n            \"전체 평균순위\": f\"{eval_data['mean_rank']:.1f}\"\n        })\n\nsummary_df = pd.DataFrame(summary_data)\nsummary_df"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Golden Set 상세 순위"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Golden Set 순위 비교\n",
    "golden_ranks_data = []\n",
    "\n",
    "for model_key in [\"solar\", \"openai\", \"multilingual_e5\"]:\n",
    "    if model_key in results and \"evaluation\" in results[model_key]:\n",
    "        model_name = results[model_key][\"model\"].split(\" (\")[0]\n",
    "        for g in results[model_key][\"evaluation\"][\"golden_ranks\"]:\n",
    "            golden_ranks_data.append({\n",
    "                \"모델\": model_name,\n",
    "                \"법안\": g[\"bill_name\"][:20] + \"...\",\n",
    "                \"난이도\": g[\"difficulty\"],\n",
    "                \"순위\": g[\"rank\"],\n",
    "                \"유사도\": round(g[\"similarity\"], 3)\n",
    "            })\n",
    "\n",
    "ranks_df = pd.DataFrame(golden_ranks_data)\n",
    "ranks_pivot = ranks_df.pivot_table(\n",
    "    index=[\"법안\", \"난이도\"],\n",
    "    columns=\"모델\",\n",
    "    values=\"순위\",\n",
    "    aggfunc=\"first\"\n",
    ").reset_index()\n",
    "ranks_pivot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 한글 폰트 설정\n",
    "plt.rcParams['font.family'] = 'Malgun Gothic'\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# 1. 순위 비교 바 차트\n",
    "models = [\"Solar\", \"OpenAI\", \"E5\"]\n",
    "colors = [\"#FF6B6B\", \"#4ECDC4\", \"#45B7D1\"]\n",
    "\n",
    "for model_key, model_name, color in zip(\n",
    "    [\"solar\", \"openai\", \"multilingual_e5\"],\n",
    "    models,\n",
    "    colors\n",
    "):\n",
    "    if model_key in results and \"evaluation\" in results[model_key]:\n",
    "        ranks = [g[\"rank\"] for g in results[model_key][\"evaluation\"][\"golden_ranks\"]]\n",
    "        x_pos = [0, 1, 2, 3, 4]\n",
    "        offset = (models.index(model_name) - 1) * 0.25\n",
    "        axes[0].bar([x + offset for x in x_pos], ranks, 0.25, label=model_name, color=color, alpha=0.8)\n",
    "\n",
    "axes[0].set_xlabel(\"Golden Set 법안\")\n",
    "axes[0].set_ylabel(\"순위 (낮을수록 좋음)\")\n",
    "axes[0].set_title(\"모델별 Golden Set 순위\")\n",
    "axes[0].set_xticks(range(5))\n",
    "axes[0].set_xticklabels([\"탄소중립\\n(Easy)\", \"중대재해\\n(Easy)\", \"개인정보\\n(Medium)\", \"약사법\\n(Hard)\", \"국유재산\\n(Hard)\"], fontsize=9)\n",
    "axes[0].legend()\n",
    "axes[0].axhline(y=10, color='red', linestyle='--', alpha=0.5)\n",
    "axes[0].axhline(y=50, color='orange', linestyle='--', alpha=0.5)\n",
    "\n",
    "# 2. Hard 난이도 순위 비교\n",
    "hard_ranks = {}\n",
    "for model_key, model_name in zip([\"solar\", \"openai\", \"multilingual_e5\"], models):\n",
    "    if model_key in results and \"evaluation\" in results[model_key]:\n",
    "        hard = [g[\"rank\"] for g in results[model_key][\"evaluation\"][\"golden_ranks\"] if g[\"difficulty\"] == \"Hard\"]\n",
    "        hard_ranks[model_name] = hard\n",
    "\n",
    "ax2 = axes[1]\n",
    "x = range(len(models))\n",
    "width = 0.35\n",
    "yaksa = [hard_ranks[m][0] for m in models]\n",
    "guyu = [hard_ranks[m][1] for m in models]\n",
    "\n",
    "bars1 = ax2.bar([i - width/2 for i in x], yaksa, width, label='약사법', color='#FF6B6B')\n",
    "bars2 = ax2.bar([i + width/2 for i in x], guyu, width, label='국유재산특례제한법', color='#4ECDC4')\n",
    "\n",
    "ax2.set_xlabel(\"모델\")\n",
    "ax2.set_ylabel(\"순위\")\n",
    "ax2.set_title(\"Hard 난이도 법안 순위 비교\")\n",
    "ax2.set_xticks(x)\n",
    "ax2.set_xticklabels(models)\n",
    "ax2.legend()\n",
    "ax2.axhline(y=50, color='orange', linestyle='--', alpha=0.5)\n",
    "\n",
    "for bar in bars1:\n",
    "    ax2.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 1, f'{int(bar.get_height())}', ha='center', va='bottom', fontsize=10)\n",
    "for bar in bars2:\n",
    "    ax2.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 1, f'{int(bar.get_height())}', ha='center', va='bottom', fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 분석\n",
    "\n",
    "### 4.1 주요 발견\n",
    "\n",
    "1. **법안명만으로는 Cross-Domain 감지가 매우 어려움**\n",
    "   - 3개 모델 모두 Recall@10 = 0%\n",
    "   - Golden Set이 Top 10에 단 1건도 진입하지 못함\n",
    "\n",
    "2. **Hard 난이도 감지력**\n",
    "   - **OpenAI 우위**: 국유재산특례제한법 #32 (가장 좋음)\n",
    "   - Solar: 국유재산특례제한법 #49\n",
    "   - E5: 약사법 #51\n",
    "\n",
    "3. **유사도 분포 특성**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 유사도 분포 분석\n",
    "sim_data = []\n",
    "for model_key, model_name in zip([\"solar\", \"openai\", \"multilingual_e5\"], [\"Solar\", \"OpenAI\", \"E5\"]):\n",
    "    if model_key in results and \"evaluation\" in results[model_key]:\n",
    "        sims = [g[\"similarity\"] for g in results[model_key][\"evaluation\"][\"golden_ranks\"]]\n",
    "        sim_data.append({\n",
    "            \"모델\": model_name,\n",
    "            \"최소 유사도\": f\"{min(sims):.3f}\",\n",
    "            \"최대 유사도\": f\"{max(sims):.3f}\",\n",
    "            \"범위\": f\"{max(sims) - min(sims):.3f}\"\n",
    "        })\n",
    "\n",
    "pd.DataFrame(sim_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Top 10 소관위 분포"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top 10 소관위 분포\n",
    "for model_key, model_name in zip([\"solar\", \"openai\", \"multilingual_e5\"], [\"Solar\", \"OpenAI\", \"E5\"]):\n",
    "    if model_key in results and \"top_10\" in results[model_key]:\n",
    "        committees = [b[\"committee\"][:15] for b in results[model_key][\"top_10\"]]\n",
    "        print(f\"\\n[{model_name}] Top 10 소관위 분포:\")\n",
    "        for c, cnt in pd.Series(committees).value_counts().items():\n",
    "            print(f\"  - {c}: {cnt}건\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 한계점 및 개선 방향\n",
    "\n",
    "### 5.1 현재 테스트의 한계\n",
    "\n",
    "| 한계점 | 설명 |\n",
    "|--------|------|\n",
    "| **법안명만 사용** | 제안이유, 주요내용 등 본문 미포함 |\n",
    "| **의미적 정보 부족** | 짧은 법안명으로는 Cross-Domain 연관성 파악 어려움 |\n",
    "| **Golden Set 규모** | 5건으로 통계적 유의성 제한적 |\n",
    "\n",
    "### 5.2 개선 방향\n",
    "\n",
    "1. **법안 본문 수집** - 열린국회정보 API에서 제안이유/주요내용 수집\n",
    "2. **본문 포함 재테스트** - 의미적 유사도 정확도 향상 기대\n",
    "3. **Reranker 추가** - 초기 검색 후 정밀 재순위화"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 결론\n",
    "\n",
    "### 6.1 v1 테스트 결과 요약\n",
    "\n",
    "- **Winner (Hard 감지 기준)**: OpenAI text-embedding-3-small\n",
    "  - Hard 평균 순위 45.0으로 가장 우수\n",
    "  - 국유재산특례제한법 #32로 가장 높은 순위 기록\n",
    "\n",
    "- **차선**: Solar Embedding (Upstage)\n",
    "  - Hard 평균 순위 52.0\n",
    "  - 한국어 특화 모델로서 잠재력 있음\n",
    "\n",
    "### 6.2 다음 단계\n",
    "\n",
    "**v2 테스트**: 법안 본문(제안이유) 포함 후 재테스트 예정\n",
    "\n",
    "---\n",
    "\n",
    "*Generated: 2026-01-15*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}